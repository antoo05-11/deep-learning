{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 7062607,
     "sourceType": "datasetVersion",
     "datasetId": 4066114
    }
   ],
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "def _data_train(fn):\n",
    "    with open(fn, 'r') as fn:\n",
    "        train = fn.readlines()\n",
    "    train = [item[:-1] for item in train[:40000]]\n",
    "    return train\n",
    "\n",
    "\n",
    "train = _data_train(fn='phap-luat.txt')\n",
    "print('length of train: {}'.format(len(train)))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:16.850567Z",
     "iopub.execute_input": "2024-01-13T10:24:16.850881Z",
     "iopub.status.idle": "2024-01-13T10:24:16.942175Z",
     "shell.execute_reply.started": "2024-01-13T10:24:16.850857Z",
     "shell.execute_reply": "2024-01-13T10:24:16.941233Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:49:45.344261776Z",
     "start_time": "2024-01-15T00:49:45.224528727Z"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train: 9453\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# encoding=utf8\n",
    "import codecs\n",
    "import csv\n",
    "import re\n",
    "import sys\n",
    "\n",
    "\n",
    "# sys.setdefaultencoding('utf8')\n",
    "\n",
    "def remove_tone_line(utf8_str):\n",
    "    intab_l = \"ạảãàáâậầấẩẫăắằặẳẵóòọõỏôộổỗồốơờớợởỡéèẻẹẽêếềệểễúùụủũưựữửừứíìịỉĩýỳỷỵỹđ\"\n",
    "    intab_u = \"ẠẢÃÀÁÂẬẦẤẨẪĂẮẰẶẲẴÓÒỌÕỎÔỘỔỖỒỐƠỜỚỢỞỠÉÈẺẸẼÊẾỀỆỂỄÚÙỤỦŨƯỰỮỬỪỨÍÌỊỈĨÝỲỶỴỸĐ\"\n",
    "    intab = list(intab_l + intab_u)\n",
    "\n",
    "    outtab_l = \"a\" * 17 + \"o\" * 17 + \"e\" * 11 + \"u\" * 11 + \"i\" * 5 + \"y\" * 5 + \"d\"\n",
    "    outtab_u = \"A\" * 17 + \"O\" * 17 + \"E\" * 11 + \"U\" * 11 + \"I\" * 5 + \"Y\" * 5 + \"D\"\n",
    "    outtab = outtab_l + outtab_u\n",
    "\n",
    "    r = re.compile(\"|\".join(intab))\n",
    "    replaces_dict = dict(zip(intab, outtab))\n",
    "    return r.sub(lambda m: replaces_dict[m.group(0)], utf8_str)\n",
    "\n",
    "\n",
    "remove_tone_line('Đi một ngày đàng học 1 sàng khôn')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:16.944148Z",
     "iopub.execute_input": "2024-01-13T10:24:16.944601Z",
     "iopub.status.idle": "2024-01-13T10:24:16.957217Z",
     "shell.execute_reply.started": "2024-01-13T10:24:16.944566Z",
     "shell.execute_reply": "2024-01-13T10:24:16.956313Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:49:45.369666774Z",
     "start_time": "2024-01-15T00:49:45.323248413Z"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'Di mot ngay dang hoc 1 sang khon'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Tách dấu ra khỏi từ\n",
    "def normalizeString(s):\n",
    "    # Tách dấu câu nếu kí tự liền nhau\n",
    "    marks = '[.!?,-${}()]'\n",
    "    r = \"([\" + \"\\\\\".join(marks) + \"])\"\n",
    "    s = re.sub(r, r\" \\1 \", s)\n",
    "    # Thay thế nhiều spaces bằng 1 space.\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "normalizeString('vui vẻ, hòa đồng, hoạt bát')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:16.958311Z",
     "iopub.execute_input": "2024-01-13T10:24:16.958599Z",
     "iopub.status.idle": "2024-01-13T10:24:16.969849Z",
     "shell.execute_reply.started": "2024-01-13T10:24:16.958575Z",
     "shell.execute_reply": "2024-01-13T10:24:16.968935Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:49:45.431115343Z",
     "start_time": "2024-01-15T00:49:45.323985898Z"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_80701/2597581317.py:6: FutureWarning: Possible nested set at position 2\n",
      "  s = re.sub(r, r\" \\1 \", s)\n"
     ]
    },
    {
     "data": {
      "text/plain": "'vui vẻ , hòa đồng , hoạt bát'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "\n",
    "train = [normalizeString(item) for item in train]\n",
    "train_rev_accent = [remove_tone_line(item) for item in train]\n",
    "\n",
    "print('train top 5:', train[:5])\n",
    "print('train_rev_accent top 5:', train_rev_accent[:5])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:16.971973Z",
     "iopub.execute_input": "2024-01-13T10:24:16.972267Z",
     "iopub.status.idle": "2024-01-13T10:24:18.573172Z",
     "shell.execute_reply.started": "2024-01-13T10:24:16.972244Z",
     "shell.execute_reply": "2024-01-13T10:24:18.572296Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:49:47.339115419Z",
     "start_time": "2024-01-15T00:49:45.346352519Z"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train top 5: ['Phát hiện xe đò buộc hành khách trên mui , phủ bạt ( NLĐ ) - Hồi 9 giờ 30 phút ngày 13 - 2 , trong lúc làm nhiệm vụ trên tuyến Quốc lộ 1A thuộc địa phận thị trấn Đồng Cát , huyện Mộ Đức ( Quảng Ngãi ) , lực lượng cảnh sát giao thông và Thanh tra Giao thông Quảng Ngãi đã phát hiện xe khách mang biển kiểm soát 36L - 6803 do Lê Đình Thịnh ( 1977 ) , thường trú tại Thanh Hóa điều khiển chạy hướng Bắc - Nam chở đến 122 người .', 'Ngoài 115 người chật cứng trong xe , nhà xe còn đưa 7 hành khách khác lên nằm trên mui xe , dùng dây buộc và phủ bạt nhằm qua mắt các lực lượng kiểm soát . Điều đáng nói là số hành khách nằm trên mui xe đi suốt từ Thanh Hóa vào Quảng Ngãi thì mới bị phát hiện . . Lúc 15 giờ 30 phút ngày 13 - 2 , trong lúc đi tuần tra trên tuyến đường Ông Ích Đường , Công an quận Cẩm Lệ , TP Đà Nẵng đã phát hiện chiếc xe khách 38H - 4931 do tài xế Trần Quang Vinh ( sinh 1967 , Hà Tĩnh ) điều khiển , chạy tuyến Hà Tĩnh - TPHCM , trên xe có tới 100 hành khách , trong khi xe chỉ được phép chở 52 người . Công an quận Cẩm Lệ đã cho chuyển khách qua các chuyến xe khác tiếp tục vào Nam , đồng thời giam giữ xe 38H - 4931 để xử lý .', 'Kẻ giết người ra đầu thú ( NLĐ ) - Nguyễn Ngọc Tân , ngụ ấp Tân Quang , xã Đông Thạnh , huyện Cần Giuộc ( Long An ) vào ngày 4 - 1 đến cơ quan công an địa phương thú tội vì đã đâm chết anh Phan Tấn Cần , ngụ tại xã Long Phụng . Tân cùng một nhóm thanh niên không cho anh Cần vào chơi bi da vì muốn nhóm của y độc chiếm các bàn trong đó . Trong lúc anh Cần thắc mắc với chủ quán bi da thì Tân nhào tới đâm 4 nhát vào vào bụng nạn nhân rồi bỏ trốn . Anh Cần chết ngay tại chỗ .', 'Mai “cổ” làm bằng . . . xi măng Cây mai cổ được bán với giá 750 . 000 đồng ( NLĐ ) - Sáng 4 - 1 , Công an phường 13 , quận 3 - TPHCM xử lý một người bán mai cổ giả . Đó là Tạ Thị Tươi ( sinh năm 1977 ) , quê Hải Dương , hiện đang tạm trú tại đường Phạm Văn Chiêu , phường 12 , quận Gò Vấp .', 'Sáng sớm cùng ngày , chủ một căn nhà ở đường Lê Văn Sỹ , quận 3 “canh me” và bắt Tươi khi thị bán cây mai cổ với giá 750 . 000 đồng , đưa đến công an phường .']\n",
      "train_rev_accent top 5: ['Phat hien xe do buoc hanh khach tren mui , phu bat ( NLD ) - Hoi 9 gio 30 phut ngay 13 - 2 , trong luc lam nhiem vu tren tuyen Quoc lo 1A thuoc dia phan thi tran Dong Cat , huyen Mo Duc ( Quang Ngai ) , luc luong canh sat giao thong va Thanh tra Giao thong Quang Ngai da phat hien xe khach mang bien kiem soat 36L - 6803 do Le Dinh Thinh ( 1977 ) , thuong tru tai Thanh Hoa dieu khien chay huong Bac - Nam cho den 122 nguoi .', 'Ngoai 115 nguoi chat cung trong xe , nha xe con dua 7 hanh khach khac len nam tren mui xe , dung day buoc va phu bat nham qua mat cac luc luong kiem soat . Dieu dang noi la so hanh khach nam tren mui xe di suot tu Thanh Hoa vao Quang Ngai thi moi bi phat hien . . Luc 15 gio 30 phut ngay 13 - 2 , trong luc di tuan tra tren tuyen duong Ong Ich Duong , Cong an quan Cam Le , TP Da Nang da phat hien chiec xe khach 38H - 4931 do tai xe Tran Quang Vinh ( sinh 1967 , Ha Tinh ) dieu khien , chay tuyen Ha Tinh - TPHCM , tren xe co toi 100 hanh khach , trong khi xe chi duoc phep cho 52 nguoi . Cong an quan Cam Le da cho chuyen khach qua cac chuyen xe khac tiep tuc vao Nam , dong thoi giam giu xe 38H - 4931 de xu ly .', 'Ke giet nguoi ra dau thu ( NLD ) - Nguyen Ngoc Tan , ngu ap Tan Quang , xa Dong Thanh , huyen Can Giuoc ( Long An ) vao ngay 4 - 1 den co quan cong an dia phuong thu toi vi da dam chet anh Phan Tan Can , ngu tai xa Long Phung . Tan cung mot nhom thanh nien khong cho anh Can vao choi bi da vi muon nhom cua y doc chiem cac ban trong do . Trong luc anh Can thac mac voi chu quan bi da thi Tan nhao toi dam 4 nhat vao vao bung nan nhan roi bo tron . Anh Can chet ngay tai cho .', 'Mai “co” lam bang . . . xi mang Cay mai co duoc ban voi gia 750 . 000 dong ( NLD ) - Sang 4 - 1 , Cong an phuong 13 , quan 3 - TPHCM xu ly mot nguoi ban mai co gia . Do la Ta Thi Tuoi ( sinh nam 1977 ) , que Hai Duong , hien dang tam tru tai duong Pham Van Chieu , phuong 12 , quan Go Vap .', 'Sang som cung ngay , chu mot can nha o duong Le Van Sy , quan 3 “canh me” va bat Tuoi khi thi ban cay mai co voi gia 750 . 000 dong , dua den cong an phuong .']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Default word tokens\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3  # Count SOS, EOS, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3  # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:18.574551Z",
     "iopub.execute_input": "2024-01-13T10:24:18.574926Z",
     "iopub.status.idle": "2024-01-13T10:24:18.585728Z",
     "shell.execute_reply.started": "2024-01-13T10:24:18.574893Z",
     "shell.execute_reply": "2024-01-13T10:24:18.584841Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:49:47.394158234Z",
     "start_time": "2024-01-15T00:49:47.341474636Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def _ngram(text, length=4):\n",
    "    words = text.split()\n",
    "    grams = []\n",
    "    if len(words) <= length:\n",
    "        words = words + [\"PAD\"] * (length - len(words))\n",
    "        return [' '.join(words)]\n",
    "    else:\n",
    "        for i in range(len(words) - length + 1):\n",
    "            grams.append(' '.join(words[i:(i + length)]))\n",
    "        return grams\n",
    "\n",
    "\n",
    "print(_ngram('mùa đông năm nay không còn lạnh nữa. Vì đã có gấu 37 độ ấm'))\n",
    "print(_ngram('mùa đông'))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:18.587064Z",
     "iopub.execute_input": "2024-01-13T10:24:18.587380Z",
     "iopub.status.idle": "2024-01-13T10:24:18.600672Z",
     "shell.execute_reply.started": "2024-01-13T10:24:18.587347Z",
     "shell.execute_reply": "2024-01-13T10:24:18.599769Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:49:47.395888730Z",
     "start_time": "2024-01-15T00:49:47.387767812Z"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mùa đông năm nay', 'đông năm nay không', 'năm nay không còn', 'nay không còn lạnh', 'không còn lạnh nữa.', 'còn lạnh nữa. Vì', 'lạnh nữa. Vì đã', 'nữa. Vì đã có', 'Vì đã có gấu', 'đã có gấu 37', 'có gấu 37 độ', 'gấu 37 độ ấm']\n",
      "['mùa đông PAD PAD']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "\n",
    "train_grams = list(itertools.chain.from_iterable([_ngram(item) for item in train]))\n",
    "train_rev_acc_grams = list(itertools.chain.from_iterable([_ngram(item) for item in train_rev_accent]))\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:18.601639Z",
     "iopub.execute_input": "2024-01-13T10:24:18.601881Z",
     "iopub.status.idle": "2024-01-13T10:24:20.050905Z",
     "shell.execute_reply.started": "2024-01-13T10:24:18.601860Z",
     "shell.execute_reply": "2024-01-13T10:24:20.049938Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:49:48.861879412Z",
     "start_time": "2024-01-15T00:49:47.388194064Z"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "corpus = list(zip(train_rev_acc_grams, train_grams))\n",
    "corpus[:5]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:20.052343Z",
     "iopub.execute_input": "2024-01-13T10:24:20.052759Z",
     "iopub.status.idle": "2024-01-13T10:24:20.301515Z",
     "shell.execute_reply.started": "2024-01-13T10:24:20.052727Z",
     "shell.execute_reply": "2024-01-13T10:24:20.300613Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:49:49.029608129Z",
     "start_time": "2024-01-15T00:49:49.024350451Z"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[('Phat hien xe do', 'Phát hiện xe đò'),\n ('hien xe do buoc', 'hiện xe đò buộc'),\n ('xe do buoc hanh', 'xe đò buộc hành'),\n ('do buoc hanh khach', 'đò buộc hành khách'),\n ('buoc hanh khach tren', 'buộc hành khách trên')]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import unicodedata\n",
    "import os\n",
    "\n",
    "MAX_LENGTH = 4  # Maximum sentence length to consider\n",
    "\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    # Tách dấu câu nếu kí tự liền nhau\n",
    "    s = re.sub(r\"([.!?,\\-\\&\\(\\)\\[\\]])\", r\" \\1 \", s)\n",
    "    # Thay thế nhiều spaces bằng 1 space.\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "# Read query/response pairs and return a voc object\n",
    "def readVocs(lines, corpus_name='corpus'):\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(str(s)) for s in l] for l in lines]\n",
    "    voc = Voc(corpus_name)\n",
    "    return voc, pairs\n",
    "\n",
    "\n",
    "voc, pairs = readVocs(corpus)\n",
    "\n",
    "\n",
    "# Returns True iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "def filterPair(p):\n",
    "    # Input sequences need to preserve the last word for EOS token\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "\n",
    "# Filter pairs using filterPair condition\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "\n",
    "# # Using the functions defined above, return a populated voc object and pairs list\n",
    "def loadPrepareData(voc, pairs):\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    # pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words:\", voc.num_words)\n",
    "    return voc, pairs\n",
    "\n",
    "\n",
    "# Load/Assemble voc and pairs\n",
    "save_dir = os.path.join(\"data\", \"save\")\n",
    "voc, pairs = loadPrepareData(voc, pairs)\n",
    "# Print some pairs to validate\n",
    "print(\"\\npairs:\")\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:20.303147Z",
     "iopub.execute_input": "2024-01-13T10:24:20.303505Z",
     "iopub.status.idle": "2024-01-13T10:24:42.430570Z",
     "shell.execute_reply.started": "2024-01-13T10:24:20.303472Z",
     "shell.execute_reply": "2024-01-13T10:24:42.429622Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:50:05.122417062Z",
     "start_time": "2024-01-15T00:49:49.028279381Z"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 981096 sentence pairs\n",
      "Trimmed to 981096 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 22043\n",
      "\n",
      "pairs:\n",
      "['Phat hien xe do', 'Phát hiện xe đò']\n",
      "['hien xe do buoc', 'hiện xe đò buộc']\n",
      "['xe do buoc hanh', 'xe đò buộc hành']\n",
      "['do buoc hanh khach', 'đò buộc hành khách']\n",
      "['buoc hanh khach tren', 'buộc hành khách trên']\n",
      "['hanh khach tren mui', 'hành khách trên mui']\n",
      "['khach tren mui ,', 'khách trên mui ,']\n",
      "['tren mui , phu', 'trên mui , phủ']\n",
      "['mui , phu bat', 'mui , phủ bạt']\n",
      "[', phu bat (', ', phủ bạt (']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "MIN_COUNT = 3  # Minimum word count threshold for trimming\n",
    "\n",
    "\n",
    "def trimRareWords(voc, pairs, MIN_COUNT):\n",
    "    # Trim words used under the MIN_COUNT from the voc\n",
    "    voc.trim(MIN_COUNT)\n",
    "    # Filter out pairs with trimmed words\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        # Check input sentence\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        # Check output sentence\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "\n",
    "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "\n",
    "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs),\n",
    "                                                                len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs\n",
    "\n",
    "\n",
    "# Trim voc and pairs\n",
    "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:42.434029Z",
     "iopub.execute_input": "2024-01-13T10:24:42.434785Z",
     "iopub.status.idle": "2024-01-13T10:24:44.777195Z",
     "shell.execute_reply.started": "2024-01-13T10:24:42.434757Z",
     "shell.execute_reply": "2024-01-13T10:24:44.776210Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:50:06.730950516Z",
     "start_time": "2024-01-15T00:50:05.165003785Z"
    }
   },
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_words 21411 / 22040 = 0.9715\n",
      "Trimmed from 981096 pairs to 980513, 0.9994 of total\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print('EOS_token: ', EOS_token)\n",
    "print('SOS_token: ', SOS_token)\n",
    "print('PAD_token: ', PAD_token)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:44.778480Z",
     "iopub.execute_input": "2024-01-13T10:24:44.778767Z",
     "iopub.status.idle": "2024-01-13T10:24:44.783851Z",
     "shell.execute_reply.started": "2024-01-13T10:24:44.778743Z",
     "shell.execute_reply": "2024-01-13T10:24:44.782860Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:50:06.738124457Z",
     "start_time": "2024-01-15T00:50:06.733024886Z"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS_token:  2\n",
      "SOS_token:  1\n",
      "PAD_token:  0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "\n",
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "\n",
    "# Padding thêm 0 vào list nào có độ dài nhỏ hơn về phía bên phải\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "\n",
    "# Tạo ma trận binary có kích thước như ma trận truyền vào l nhưng giá trị của mỗi phần tử đánh dấu 1 hoặc 0 tương ứng với padding hoặc không padding\n",
    "def binaryMatrix(l, value=PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "\n",
    "# Returns padded input sequence tensor and lengths\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "\n",
    "# Returns padded target sequence tensor, padding mask, and max target length\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "\n",
    "# Returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n",
    "\n",
    "\n",
    "# Example for validation\n",
    "small_batch_size = 4\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:44.785292Z",
     "iopub.execute_input": "2024-01-13T10:24:44.785573Z",
     "iopub.status.idle": "2024-01-13T10:24:44.822481Z",
     "shell.execute_reply.started": "2024-01-13T10:24:44.785549Z",
     "shell.execute_reply": "2024-01-13T10:24:44.821689Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:50:08.932966110Z",
     "start_time": "2024-01-15T00:50:06.761776933Z"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"input_variable: \\n\", input_variable)\n",
    "print(\"lengths: \\n\", lengths)\n",
    "print(\"target_variable: \\n\", target_variable)\n",
    "print(\"mask: \\n\", mask)\n",
    "print(\"max_target_len: \\n\", max_target_len)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:44.823537Z",
     "iopub.execute_input": "2024-01-13T10:24:44.823792Z",
     "iopub.status.idle": "2024-01-13T10:24:44.845439Z",
     "shell.execute_reply.started": "2024-01-13T10:24:44.823770Z",
     "shell.execute_reply": "2024-01-13T10:24:44.844604Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:50:08.969909831Z",
     "start_time": "2024-01-15T00:50:08.936803564Z"
    }
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: \n",
      " tensor([[1110,  304,  239,  213],\n",
      "        [ 188,  592,  213, 1044],\n",
      "        [4490, 1448, 1044,  619],\n",
      "        [ 434,  145,  349, 2285],\n",
      "        [   2,    2,    2,    2]])\n",
      "lengths: \n",
      " tensor([5, 5, 5, 5])\n",
      "target_variable: \n",
      " tensor([[1111,  305,  240,  213],\n",
      "        [ 189,  592,  213, 1226],\n",
      "        [4491, 1449, 1226, 1237],\n",
      "        [ 435,  854,  350, 3190],\n",
      "        [   2,    2,    2,    2]])\n",
      "mask: \n",
      " tensor([[1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1],\n",
      "        [1, 1, 1, 1]], dtype=torch.uint8)\n",
      "max_target_len: \n",
      " 5\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:44.846529Z",
     "iopub.execute_input": "2024-01-13T10:24:44.846856Z",
     "iopub.status.idle": "2024-01-13T10:24:44.853402Z",
     "shell.execute_reply.started": "2024-01-13T10:24:44.846825Z",
     "shell.execute_reply": "2024-01-13T10:24:44.852540Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:50:08.972830344Z",
     "start_time": "2024-01-15T00:50:08.964293344Z"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
    "        # set bidirectional = True for bidirectional\n",
    "        # https://pytorch.org/docs/stable/nn.html?highlight=gru#torch.nn.GRU to get more information\n",
    "        self.gru = nn.GRU(input_size=hidden_size,  # number of expected feature of input x \n",
    "                          hidden_size=hidden_size,  # number of expected feature of hidden state \n",
    "                          num_layers=n_layers,  # number of GRU layers\n",
    "                          dropout=(0 if n_layers == 1 else dropout),  # dropout probability apply in encoder network\n",
    "                          bidirectional=True  # one or two directions.\n",
    "                          )\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        # Step 1: Convert word indexes to embeddings\n",
    "        # shape: (max_length , batch_size , hidden_size)\n",
    "        embedded = self.embedding(input_seq)\n",
    "        # Pack padded batch of sequences for RNN module. Padding zero when length less than max_length of input_lengths.\n",
    "        # shape: (max_length , batch_size , hidden_size)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        # Step 2: Forward packed through GRU\n",
    "        # outputs is output of final GRU layer\n",
    "        # hidden is concatenate of all hidden states corresponding with each time step.\n",
    "        # outputs shape: (max_length , batch_size , hidden_size x num_directions)\n",
    "        # hidden shape: (n_layers x num_directions , batch_size , hidden_size)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        # Unpack padding. Revert of pack_padded_sequence\n",
    "        # outputs shape: (max_length , batch_size , hidden_size x num_directions)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        # Sum bidirectional GRU outputs to reshape shape into (max_length , batch_size , hidden_size)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]\n",
    "        # outputs shape:(max_length , batch_size , hidden_size)\n",
    "        # hidden shape: (n_layers x num_directions , batch_size , hidden_size)\n",
    "        return outputs, hidden"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:44.854745Z",
     "iopub.execute_input": "2024-01-13T10:24:44.855094Z",
     "iopub.status.idle": "2024-01-13T10:24:44.867736Z",
     "shell.execute_reply.started": "2024-01-13T10:24:44.855068Z",
     "shell.execute_reply": "2024-01-13T10:24:44.866924Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:50:09.017597275Z",
     "start_time": "2024-01-15T00:50:08.973825458Z"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Thử nghiệm phrase Encoder bằng cách giả lập 1 mạng Encoder với:\n",
    "from torch import nn\n",
    "\n",
    "hidden_size = 3\n",
    "n_layers = 7\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "print('input_seq: \\n', input_variable)\n",
    "print('input_lengths: \\n', lengths)\n",
    "encoder = EncoderRNN(hidden_size=hidden_size, embedding=embedding, n_layers=n_layers)\n",
    "\n",
    "print('encoder phrase: \\n', encoder)\n",
    "\n",
    "output, hidden = encoder.forward(input_seq=input_variable, input_lengths=lengths)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:44.868767Z",
     "iopub.execute_input": "2024-01-13T10:24:44.869056Z",
     "iopub.status.idle": "2024-01-13T10:24:44.979038Z",
     "shell.execute_reply.started": "2024-01-13T10:24:44.869021Z",
     "shell.execute_reply": "2024-01-13T10:24:44.978065Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:50:09.063642319Z",
     "start_time": "2024-01-15T00:50:09.015970322Z"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_seq: \n",
      " tensor([[1110,  304,  239,  213],\n",
      "        [ 188,  592,  213, 1044],\n",
      "        [4490, 1448, 1044,  619],\n",
      "        [ 434,  145,  349, 2285],\n",
      "        [   2,    2,    2,    2]])\n",
      "input_lengths: \n",
      " tensor([5, 5, 5, 5])\n",
      "encoder phrase: \n",
      " EncoderRNN(\n",
      "  (embedding): Embedding(21414, 3)\n",
      "  (gru): GRU(3, 3, num_layers=7, bidirectional=True)\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print('output size: ', output.size())\n",
    "print('hidden size: ', hidden.size())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:44.980458Z",
     "iopub.execute_input": "2024-01-13T10:24:44.980778Z",
     "iopub.status.idle": "2024-01-13T10:24:44.985836Z",
     "shell.execute_reply.started": "2024-01-13T10:24:44.980753Z",
     "shell.execute_reply": "2024-01-13T10:24:44.984850Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:50:09.066153799Z",
     "start_time": "2024-01-15T00:50:09.059926070Z"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size:  torch.Size([5, 4, 3])\n",
      "hidden size:  torch.Size([14, 4, 3])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        # encoder_output shape:(max_length , batch_size , hidden_size)\n",
    "        # hidden shape: (1 , batch_size , hidden_size)\n",
    "        # return shape: (max_length, batch_size)\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "\n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        # encoder_output shape:(max_length , batch_size , hidden_size)\n",
    "        # hidden shape: (batch_size , hidden_size)\n",
    "        # energy shape: (max_length , batch_size , hidden_size)\n",
    "        # return shape: (max_length , batch_size)\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "\n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        # encoder_output shape:(max_length , batch_size , hidden_size)\n",
    "        # hidden shape: (batch_size , hidden_size)\n",
    "        # energy shape: (max_length , batch_size , 2*hidden_size)\n",
    "        # self.v shape: (hidden_size)\n",
    "        # return shape: (max_length , batch_size)\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # Calculate the attention weights (energies) based on the given method\n",
    "        # attn_energies.shape: (max_length , batch_size)\n",
    "        if self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "\n",
    "        # Transpose max_length and batch_size dimensions\n",
    "        # attn_energies.shape: (batch_size , max_length)\n",
    "        attn_energies = attn_energies.t()\n",
    "        # Return the softmax normalized probability scores (with added dimension)\n",
    "        attn_weights = F.softmax(attn_energies, dim=1).unsqueeze(1)\n",
    "        # attn_weights shape: (batch_size , 1 , max_length)\n",
    "        return attn_weights"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:44.987192Z",
     "iopub.execute_input": "2024-01-13T10:24:44.987460Z",
     "iopub.status.idle": "2024-01-13T10:24:45.027489Z",
     "shell.execute_reply.started": "2024-01-13T10:24:44.987436Z",
     "shell.execute_reply": "2024-01-13T10:24:45.026552Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:50:09.067396025Z",
     "start_time": "2024-01-15T00:50:09.060304396Z"
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        '''\n",
    "        input_step: list time step index of batch. shape (1 x batch_size)\n",
    "        last_hidden: last hidden output of hidden layer (we can take in right direction or left direction upon us) which have shape = (n_layers x batch_size x hidden_size)\n",
    "        encoder_outputs: output of encoder \n",
    "        '''\n",
    "        #===========================================\n",
    "        # Step 1: Embedding current sequence index\n",
    "        # Note: we run this one step (word) at a time\n",
    "        # Get embedding of current input word\n",
    "        # embedded shape: 1 x batch_size x hidden_size\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "\n",
    "        #===========================================\n",
    "        # Step 2: pass embedded and last hidden into decoder\n",
    "        # Forward through unidirectional GRU\n",
    "        # rnn_output shape: 1 x batch_size x hidden_size\n",
    "        # hidden shape: n_layers x batch_size x hidden_size\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        # Calculate attention weights from the current GRU output\n",
    "        # attn_weights shape: batch_size x 1 x max_length\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
    "        # encoder_outputs shape: max_length x batch_size x hidden_size\n",
    "        # context shape: batch_size x 1 x hidden_size\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
    "        # rnn_output shape: batch_size x hidden_size\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        # context shape: batch_size x hidden_size\n",
    "        context = context.squeeze(1)\n",
    "\n",
    "        #===========================================\n",
    "        # Step 3: calculate output probability distribution \n",
    "        # concat_input shape: batch_size x (2*hidden_size)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        # concat_output shape: batch_size x hidden_size\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        # Predict next word using Luong eq. 6\n",
    "        # output shape: output_size\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        # Return output and final hidden state\n",
    "        return output, hidden"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:45.029328Z",
     "iopub.execute_input": "2024-01-13T10:24:45.029751Z",
     "iopub.status.idle": "2024-01-13T10:24:45.045045Z",
     "shell.execute_reply.started": "2024-01-13T10:24:45.029712Z",
     "shell.execute_reply": "2024-01-13T10:24:45.044057Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:50:09.131291686Z",
     "start_time": "2024-01-15T00:50:09.103953943Z"
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "time_step = 0\n",
    "# Take all index of batch at time step 0. All words are <SOS> mark for start of sentences.\n",
    "input_step = torch.tensor([SOS_token] * small_batch_size).unsqueeze(0)\n",
    "n_layers = 7\n",
    "# take last hidden vector of encoder\n",
    "last_hidden = hidden[:n_layers]\n",
    "print('batch_size: ', small_batch_size)\n",
    "print('input_step.size at time_step 0: ', input_step.size())\n",
    "print('last_hidden.size: ', last_hidden.size())\n",
    "attn_model = 'dot'\n",
    "hidden_size = 3\n",
    "# Output size of decoder model is size of vocabulary\n",
    "output_size = len(voc.word2index)\n",
    "\n",
    "luongAttnDecoderRNN = LuongAttnDecoderRNN(attn_model=attn_model,\n",
    "                                          embedding=embedding,\n",
    "                                          hidden_size=hidden_size,\n",
    "                                          output_size=output_size,\n",
    "                                          n_layers=n_layers)\n",
    "\n",
    "print('luongAttnDecoderRNN phrase: \\n', luongAttnDecoderRNN)\n",
    "dec_output, dec_hidden = luongAttnDecoderRNN.forward(input_step=input_step,\n",
    "                                                     last_hidden=last_hidden,\n",
    "                                                     encoder_outputs=output)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:45.046446Z",
     "iopub.execute_input": "2024-01-13T10:24:45.046837Z",
     "iopub.status.idle": "2024-01-13T10:24:45.083673Z",
     "shell.execute_reply.started": "2024-01-13T10:24:45.046809Z",
     "shell.execute_reply": "2024-01-13T10:24:45.082720Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:50:09.132774448Z",
     "start_time": "2024-01-15T00:50:09.104429510Z"
    }
   },
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size:  4\n",
      "input_step.size at time_step 0:  torch.Size([1, 4])\n",
      "last_hidden.size:  torch.Size([7, 4, 3])\n",
      "luongAttnDecoderRNN phrase: \n",
      " LuongAttnDecoderRNN(\n",
      "  (embedding): Embedding(21414, 3)\n",
      "  (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (gru): GRU(3, 3, num_layers=7, dropout=0.1)\n",
      "  (concat): Linear(in_features=6, out_features=3, bias=True)\n",
      "  (out): Linear(in_features=3, out_features=21411, bias=True)\n",
      "  (attn): Attn()\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def maskNLLLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:45.084960Z",
     "iopub.execute_input": "2024-01-13T10:24:45.085272Z",
     "iopub.status.idle": "2024-01-13T10:24:45.094141Z",
     "shell.execute_reply.started": "2024-01-13T10:24:45.085247Z",
     "shell.execute_reply": "2024-01-13T10:24:45.092952Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:50:09.148893718Z",
     "start_time": "2024-01-15T00:50:09.104911254Z"
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
    "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    # Initialize variables\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    # Forward pass through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    # Set initial decoder hidden state to the encoder's final hidden state\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "    # Determine if we are using teacher forcing this iteration\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Forward batch of sequences through decoder one time step at a time\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # Teacher forcing: next input is current target\n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # No teacher forcing: next input is decoder's own current output\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "\n",
    "    # Perform backpropatation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / n_totals"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:45.096313Z",
     "iopub.execute_input": "2024-01-13T10:24:45.096658Z",
     "iopub.status.idle": "2024-01-13T10:24:45.112506Z",
     "shell.execute_reply.started": "2024-01-13T10:24:45.096610Z",
     "shell.execute_reply": "2024-01-13T10:24:45.111426Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:50:09.199859534Z",
     "start_time": "2024-01-15T00:50:09.113305369Z"
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def trainIters(model_name, voc, pairs, encoder, decoder,\n",
    "               encoder_optimizer, decoder_optimizer,\n",
    "               embedding, encoder_n_layers, decoder_n_layers,\n",
    "               save_dir, n_iteration, batch_size, print_every,\n",
    "               save_every, clip, corpus_name, loadFilename):\n",
    "    # Load batches for each iteration\n",
    "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                        for _ in range(n_iteration)]\n",
    "\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    if loadFilename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        # Extract fields from batch\n",
    "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "        print(mask)\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        print_loss += loss\n",
    "\n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration,\n",
    "                                                                                          iteration / n_iteration * 100,\n",
    "                                                                                          print_loss_avg))\n",
    "            print_loss = 0\n",
    "\n",
    "        # Save checkpoint\n",
    "        if iteration % save_every == 0:\n",
    "            directory = os.path.join(save_dir, model_name, corpus_name,\n",
    "                                     '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:45.114641Z",
     "iopub.execute_input": "2024-01-13T10:24:45.115313Z",
     "iopub.status.idle": "2024-01-13T10:24:45.128885Z",
     "shell.execute_reply.started": "2024-01-13T10:24:45.115280Z",
     "shell.execute_reply": "2024-01-13T10:24:45.127981Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:50:09.201687255Z",
     "start_time": "2024-01-15T00:50:09.156247Z"
    }
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:45.130058Z",
     "iopub.execute_input": "2024-01-13T10:24:45.130406Z",
     "iopub.status.idle": "2024-01-13T10:24:45.144086Z",
     "shell.execute_reply.started": "2024-01-13T10:24:45.130372Z",
     "shell.execute_reply": "2024-01-13T10:24:45.143238Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:50:09.203482947Z",
     "start_time": "2024-01-15T00:50:09.156644938Z"
    }
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    # Decode sentence with searcher\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    # indexes -> words\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    while (1):\n",
    "        try:\n",
    "            # Get input sentence\n",
    "            input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # Normalize sentence\n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # Format and print response sentence\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:45.145366Z",
     "iopub.execute_input": "2024-01-13T10:24:45.146025Z",
     "iopub.status.idle": "2024-01-13T10:24:45.158037Z",
     "shell.execute_reply.started": "2024-01-13T10:24:45.145971Z",
     "shell.execute_reply": "2024-01-13T10:24:45.156988Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:50:09.225470212Z",
     "start_time": "2024-01-15T00:50:09.199780606Z"
    }
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Configure models\n",
    "model_name = 'correct_spelling_model'\n",
    "corpus_name = 'corpus_aivivn'\n",
    "attn_model = 'dot'\n",
    "#attn_model = 'general'\n",
    "#attn_model = 'concat'\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 1000\n",
    "\n",
    "# Set checkpoint to load from; set to None if starting from scratch\n",
    "loadFilename = None\n",
    "checkpoint_iter = 5000\n",
    "\n",
    "# Load model if a loadFilename is provided\n",
    "if loadFilename:\n",
    "    # If loading on same machine the model was trained on\n",
    "    checkpoint = torch.load(loadFilename)\n",
    "    # If loading a model trained on GPU to CPU\n",
    "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
    "    encoder_sd = checkpoint['en']\n",
    "    decoder_sd = checkpoint['de']\n",
    "    encoder_optimizer_sd = checkpoint['en_opt']\n",
    "    decoder_optimizer_sd = checkpoint['de_opt']\n",
    "    embedding_sd = checkpoint['embedding']\n",
    "    voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "print('Building encoder and decoder ...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "# if loadFilename:\n",
    "#     embedding.load_state_dict(embedding_sd)\n",
    "# Initialize encoder & decoder models\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "if loadFilename:\n",
    "    encoder.load_state_dict(encoder_sd)\n",
    "    decoder.load_state_dict(decoder_sd)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "print('Models built and ready to go!')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:25:07.931213Z",
     "iopub.execute_input": "2024-01-13T10:25:07.931570Z",
     "iopub.status.idle": "2024-01-13T10:25:08.242042Z",
     "shell.execute_reply.started": "2024-01-13T10:25:07.931541Z",
     "shell.execute_reply": "2024-01-13T10:25:08.240959Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:50:09.499319153Z",
     "start_time": "2024-01-15T00:50:09.200179819Z"
    }
   },
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building encoder and decoder ...\n",
      "Models built and ready to go!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 500\n",
    "print_every = 100\n",
    "save_every = 200\n",
    "\n",
    "# Ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers ...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "if loadFilename:\n",
    "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
    "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
    "\n",
    "# Run training iterations\n",
    "print(\"Starting Training!\")\n",
    "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, corpus_name, loadFilename)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:45.581841Z",
     "iopub.execute_input": "2024-01-13T10:24:45.582159Z",
     "iopub.status.idle": "2024-01-13T10:24:50.865618Z",
     "shell.execute_reply.started": "2024-01-13T10:24:45.582132Z",
     "shell.execute_reply": "2024-01-13T10:24:50.864296Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-01-15T00:50:15.315385591Z",
     "start_time": "2024-01-15T00:50:09.501457513Z"
    }
   },
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimizers ...\n",
      "Starting Training!\n",
      "Initializing ...\n",
      "Training...\n",
      "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        [1, 0, 0,  ..., 0, 0, 0]], dtype=torch.uint8)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "masked_select: expected BoolTensor for mask",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 24\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# Run training iterations\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStarting Training!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 24\u001B[0m \u001B[43mtrainIters\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvoc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpairs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoder_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder_optimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m           \u001B[49m\u001B[43membedding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoder_n_layers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder_n_layers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_iteration\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m           \u001B[49m\u001B[43mprint_every\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_every\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclip\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcorpus_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloadFilename\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[23], line 25\u001B[0m, in \u001B[0;36mtrainIters\u001B[0;34m(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28mprint\u001B[39m(mask)\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# Run a training iteration with batch\u001B[39;00m\n\u001B[0;32m---> 25\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_variable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlengths\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_variable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_target_len\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m             \u001B[49m\u001B[43mdecoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoder_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclip\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m print_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# Print progress\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[22], line 40\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip, max_length)\u001B[0m\n\u001B[1;32m     38\u001B[0m decoder_input \u001B[38;5;241m=\u001B[39m target_variable[t]\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     39\u001B[0m \u001B[38;5;66;03m# Calculate and accumulate loss\u001B[39;00m\n\u001B[0;32m---> 40\u001B[0m mask_loss, nTotal \u001B[38;5;241m=\u001B[39m \u001B[43mmaskNLLLoss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdecoder_output\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_variable\u001B[49m\u001B[43m[\u001B[49m\u001B[43mt\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m[\u001B[49m\u001B[43mt\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     41\u001B[0m loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m mask_loss\n\u001B[1;32m     42\u001B[0m print_losses\u001B[38;5;241m.\u001B[39mappend(mask_loss\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;241m*\u001B[39m nTotal)\n",
      "Cell \u001B[0;32mIn[21], line 4\u001B[0m, in \u001B[0;36mmaskNLLLoss\u001B[0;34m(inp, target, mask)\u001B[0m\n\u001B[1;32m      2\u001B[0m nTotal \u001B[38;5;241m=\u001B[39m mask\u001B[38;5;241m.\u001B[39msum()\n\u001B[1;32m      3\u001B[0m crossEntropy \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlog(torch\u001B[38;5;241m.\u001B[39mgather(inp, \u001B[38;5;241m1\u001B[39m, target\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m))\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m----> 4\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mcrossEntropy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmasked_select\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mmean()\n\u001B[1;32m      5\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss, nTotal\u001B[38;5;241m.\u001B[39mitem()\n",
      "\u001B[0;31mRuntimeError\u001B[0m: masked_select: expected BoolTensor for mask"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "# Begin chatting (uncomment and run the following line to begin)\n",
    "evaluateInput(encoder, decoder, searcher, voc)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-13T10:24:50.866414Z",
     "iopub.status.idle": "2024-01-13T10:24:50.866751Z",
     "shell.execute_reply.started": "2024-01-13T10:24:50.866595Z",
     "shell.execute_reply": "2024-01-13T10:24:50.866611Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2024-01-15T00:50:15.311789392Z"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
